{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TDNuJ8Q66ssB",
    "outputId": "110c7d49-ae56-49bb-d0a2-dc8401b6419c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: notebook in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (7.0.7)\n",
      "Requirement already satisfied: ipywidgets in ./.local/lib/python3.9/site-packages (8.1.6)\n",
      "Requirement already satisfied: tensorboard in ./.local/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: wandb in ./.local/lib/python3.9/site-packages (0.19.9)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.9/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (2.12.5)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (2.25.2)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (4.0.12)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (6.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.local/lib/python3.9/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in ./.local/lib/python3.9/site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: absl-py>=0.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.local/lib/python3.9/site-packages (from tensorboard) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.9/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: packaging in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.local/lib/python3.9/site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>1.9 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.9/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.9/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in ./.local/lib/python3.9/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.local/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: eval-type-backport in ./.local/lib/python3.9/site-packages (from wandb) (0.2.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.local/lib/python3.9/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3 in ./.local/lib/python3.9/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.local/lib/python3.9/site-packages (from wandb) (2.26.1)\n",
      "Requirement already satisfied: setproctitle in ./.local/lib/python3.9/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.local/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: decorator in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.7.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.9.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.5.2)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.14.2)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.9.2)\n",
      "Requirement already satisfied: overrides in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.19.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.18.0)\n",
      "Requirement already satisfied: websocket-client in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.7.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (7.0.1)\n",
      "Requirement already satisfied: ipykernel in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (6.29.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.2.2)\n",
      "Requirement already satisfied: tomli in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: babel>=2.10 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (4.21.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyterlab<5,>=4.0.2->notebook) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.17.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.9.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.19.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (1.8.0)\n",
      "Requirement already satisfied: nest-asyncio in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (1.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: webencodings in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.4)\n",
      "Requirement already satisfied: uri-template in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.5)\n",
      "Requirement already satisfied: pycparser in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (2.20)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.8.19.20240106)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch pandas numpy requests tqdm scikit-learn notebook ipywidgets tensorboard wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z4bh6GjyAEzy",
    "outputId": "172df05c-e24e-456e-d9b5-96bd46585017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n",
      "WandB Version: 0.19.9\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.4\n",
      "Device Name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm # Use tqdm.notebook for Jupyter!\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import wandb\n",
    "\n",
    "# Ignore specific warnings if needed\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"WandB Version: {wandb.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# (Optional) Login to WandB if you haven't via CLI\n",
    "# try:\n",
    "#     wandb.login()\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not automatically log in to WandB: {e}\")\n",
    "#     print(\"Please ensure you have run 'wandb login' in your terminal or manually call wandb.login() here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eMBD4eT2AHVi",
    "outputId": "4159754b-773c-4302-d9ae-b076f6515a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set.\n",
      "WandB Project: BERT4Rec-MovieLens_opt1\n",
      "Run Name: bert4rec_ml20m_20250420_191350\n",
      "Batch Size: 512\n",
      "Hidden Units: 128\n",
      "Num Workers: 8\n",
      "Using AdamW optimizer.\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # WandB parameters\n",
    "    WANDB_PROJECT = \"BERT4Rec-MovieLens_opt1\" # Project name on WandB\n",
    "    WANDB_ENTITY = None # Your WandB username or team (optional, defaults to your default entity)\n",
    "    RUN_NAME = f\"bert4rec_ml20m_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\" # Unique run name\n",
    "\n",
    "    # Data parameters\n",
    "    DATASET_NAME = \"ml-20m\"\n",
    "    DATA_URL = f\"https://files.grouplens.org/datasets/movielens/{DATASET_NAME}.zip\"\n",
    "    DATA_DIR = \"./data_bert4rec\"\n",
    "    RATINGS_FILE = f\"{DATASET_NAME}/ratings.csv\"\n",
    "    MIN_USER_INTERACTIONS = 5\n",
    "    MIN_ITEM_INTERACTIONS = 5\n",
    "    TEST_NEG_SAMPLE_SIZE = 100\n",
    "\n",
    "    # Model parameters\n",
    "    max_len = 50\n",
    "    hidden_units = 128\n",
    "    num_blocks = 2\n",
    "    num_heads = 4\n",
    "    dropout_rate = 0.2\n",
    "    mask_prob = 0.2\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = 5\n",
    "    batch_size = 512 # Increased for V100/A100\n",
    "    lr = 1e-3\n",
    "    optimizer_type = 'AdamW'\n",
    "    weight_decay = 0.01\n",
    "    num_workers = 8\n",
    "    log_freq = 50 # Log batch loss every N batches to WandB/console\n",
    "    profiler_enabled = True # Keep profiler if needed alongside WandB\n",
    "    profile_batches = 50\n",
    "    profile_warmup = 10\n",
    "    profile_dir = \"./log_bert4rec\"\n",
    "\n",
    "    # Special token indices\n",
    "    PAD = 0\n",
    "    MASK = -1\n",
    "\n",
    "# Instantiate config\n",
    "config = Config()\n",
    "\n",
    "# --- Sanity Checks ---\n",
    "if config.hidden_units % config.num_heads != 0:\n",
    "    raise ValueError(f\"hidden_units ({config.hidden_units}) must be divisible by num_heads ({config.num_heads})\")\n",
    "\n",
    "print(\"Configuration set.\")\n",
    "print(f\"WandB Project: {config.WANDB_PROJECT}\")\n",
    "print(f\"Run Name: {config.RUN_NAME}\")\n",
    "print(f\"Batch Size: {config.batch_size}\")\n",
    "print(f\"Hidden Units: {config.hidden_units}\")\n",
    "print(f\"Num Workers: {config.num_workers}\")\n",
    "print(f\"Using {config.optimizer_type} optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sGSVMutiAJk_",
    "outputId": "0d2d493b-4778-4009-e723-065ae2eefd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download function defined.\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract_data(config):\n",
    "    \"\"\"Downloads and extracts the MovieLens dataset.\"\"\"\n",
    "    os.makedirs(config.DATA_DIR, exist_ok=True)\n",
    "    zip_path = os.path.join(config.DATA_DIR, f\"{config.DATASET_NAME}.zip\")\n",
    "    extract_path = os.path.join(config.DATA_DIR)\n",
    "    ratings_path = os.path.join(config.DATA_DIR, config.RATINGS_FILE)\n",
    "\n",
    "    if not os.path.exists(ratings_path):\n",
    "        print(f\"Downloading {config.DATASET_NAME} dataset...\")\n",
    "        response = requests.get(config.DATA_URL, stream=True)\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024 # 1 Kibibyte\n",
    "        # Use tqdm for download progress\n",
    "        progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True, desc=\"Downloading\")\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=block_size):\n",
    "                progress_bar.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "        progress_bar.close()\n",
    "        if total_size != 0 and progress_bar.n != total_size:\n",
    "             print(\"ERROR, something went wrong during download\")\n",
    "\n",
    "        print(\"Download complete. Extracting...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"Extraction complete.\")\n",
    "        os.remove(zip_path) # Clean up zip file\n",
    "    else:\n",
    "        print(f\"Dataset found at {ratings_path}\")\n",
    "\n",
    "print(\"Data download function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1ITC-eHjALeE",
    "outputId": "6d8ac846-105c-4f35-e075-084b3e916749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing function defined.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(config):\n",
    "    \"\"\"Loads ratings, filters users/items, creates sequences.\"\"\"\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    ratings_df = pd.read_csv(os.path.join(config.DATA_DIR, config.RATINGS_FILE))\n",
    "    print(f\"Initial ratings: {len(ratings_df)}\")\n",
    "\n",
    "    # Filter users\n",
    "    user_counts = ratings_df['userId'].value_counts()\n",
    "    valid_users = user_counts[user_counts >= config.MIN_USER_INTERACTIONS].index\n",
    "    ratings_df = ratings_df[ratings_df['userId'].isin(valid_users)]\n",
    "    print(f\"Ratings after user filtering: {len(ratings_df)} ({len(valid_users)} users)\")\n",
    "\n",
    "    # Filter items\n",
    "    item_counts = ratings_df['movieId'].value_counts()\n",
    "    valid_items = item_counts[item_counts >= config.MIN_ITEM_INTERACTIONS].index\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(valid_items)]\n",
    "    print(f\"Ratings after item filtering: {len(ratings_df)} ({len(valid_items)} items)\")\n",
    "\n",
    "    # Re-filter users\n",
    "    user_counts = ratings_df['userId'].value_counts()\n",
    "    valid_users = user_counts[user_counts >= config.MIN_USER_INTERACTIONS].index\n",
    "    ratings_df = ratings_df[ratings_df['userId'].isin(valid_users)]\n",
    "    print(f\"Ratings after re-filtering users: {len(ratings_df)} ({len(valid_users)} users)\")\n",
    "\n",
    "    # Sort interactions\n",
    "    ratings_df = ratings_df.sort_values(by=['userId', 'timestamp'])\n",
    "\n",
    "    # Create mappings (item IDs start from 1)\n",
    "    unique_users = ratings_df['userId'].unique()\n",
    "    user_map = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "    unique_items = ratings_df['movieId'].unique()\n",
    "    item_map = {item_id: i + 1 for i, item_id in enumerate(unique_items)}\n",
    "    num_items = len(item_map)\n",
    "    config.MASK = num_items + 1 # Set MASK token index dynamically in the shared config object\n",
    "\n",
    "    print(f\"Number of unique users: {len(user_map)}\")\n",
    "    print(f\"Number of unique items (vocab size): {num_items}\")\n",
    "    print(f\"MASK token index set to: {config.MASK}\")\n",
    "\n",
    "    # Group interactions and create sequences\n",
    "    user_sequences = ratings_df.groupby('userId')['movieId'].apply(list)\n",
    "    processed_sequences = []\n",
    "    for user_id, item_sequence in tqdm(user_sequences.items(), desc=\"Generating sequences\"):\n",
    "        mapped_sequence = [item_map[item] for item in item_sequence]\n",
    "        # Create subsequences ending at each point\n",
    "        for i in range(1, len(mapped_sequence)): # Start from 1 to have at least one item as label\n",
    "            end_idx = i + 1\n",
    "            start_idx = max(0, end_idx - config.max_len)\n",
    "            seq = mapped_sequence[start_idx:end_idx]\n",
    "\n",
    "            # Pad sequence\n",
    "            padded_seq = ([config.PAD] * (config.max_len - len(seq))) + seq\n",
    "            if len(padded_seq) != config.max_len:\n",
    "                 print(f\"Padding Error: User {user_id}, i={i}, len={len(padded_seq)}\")\n",
    "                 continue\n",
    "\n",
    "            processed_sequences.append(padded_seq)\n",
    "\n",
    "    print(f\"Total number of sequences generated: {len(processed_sequences)}\")\n",
    "\n",
    "    # Split data (user-agnostic split for simplicity here)\n",
    "    random.shuffle(processed_sequences)\n",
    "    split_idx = int(len(processed_sequences) * 0.9)\n",
    "    train_sequences = processed_sequences[:split_idx]\n",
    "    val_sequences = processed_sequences[split_idx:]\n",
    "\n",
    "    print(f\"Train sequences: {len(train_sequences)}\")\n",
    "    print(f\"Validation sequences: {len(val_sequences)}\")\n",
    "\n",
    "    return train_sequences, val_sequences, num_items, config.MASK # Return MASK index\n",
    "\n",
    "print(\"Data preprocessing function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pgh7ZQMXANaS",
    "outputId": "fab111b4-628f-4782-d512-4e669335da38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLDataset class defined.\n"
     ]
    }
   ],
   "source": [
    "class MLDataset(Dataset):\n",
    "    \"\"\"MovieLens Dataset for BERT4Rec training.\"\"\"\n",
    "    def __init__(self, sequences, max_len, mask_prob, mask_token_idx, pad_token_idx, num_items):\n",
    "        self.sequences = sequences\n",
    "        self.max_len = max_len\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token_idx = mask_token_idx\n",
    "        self.pad_token_idx = pad_token_idx\n",
    "        self.num_items = num_items # Actual number of items (vocab size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx] # Sequence of item IDs (padded)\n",
    "        masked_input_seq = list(seq)\n",
    "        labels = [self.pad_token_idx] * self.max_len # Target labels (only for masked positions)\n",
    "\n",
    "        # Identify positions eligible for masking (not PAD)\n",
    "        eligible_indices = [i for i, token in enumerate(seq) if token != self.pad_token_idx]\n",
    "        num_eligible = len(eligible_indices)\n",
    "        num_items_to_mask = max(1, math.ceil(self.mask_prob * num_eligible)) # Ensure at least one item is masked if possible\n",
    "\n",
    "        if num_eligible > 0:\n",
    "            # Randomly select indices to mask from eligible ones\n",
    "            indices_to_mask = random.sample(eligible_indices, min(num_items_to_mask, num_eligible))\n",
    "\n",
    "            for i in indices_to_mask:\n",
    "                original_item = seq[i]\n",
    "                labels[i] = original_item # Set the label to the original item\n",
    "\n",
    "                # Apply masking strategy to the input sequence\n",
    "                prob = random.random()\n",
    "                if prob < 0.8: # 80% chance: Replace with MASK token\n",
    "                    masked_input_seq[i] = self.mask_token_idx\n",
    "                elif prob < 0.9: # 10% chance: Replace with random item\n",
    "                    random_item = random.randint(1, self.num_items) # Items are 1 to num_items\n",
    "                    # Ensure random item isn't the original or PAD/MASK\n",
    "                    while random_item == original_item:\n",
    "                         random_item = random.randint(1, self.num_items)\n",
    "                    masked_input_seq[i] = random_item\n",
    "                # else: 10% chance: Keep original item (implicitly handled)\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(masked_input_seq, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "print(\"MLDataset class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qHVpWJD1APWO",
    "outputId": "50b73ca4-988f-4381-eea8-e7df792db643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT4Rec model class defined.\n"
     ]
    }
   ],
   "source": [
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, num_items, hidden_units, num_blocks, num_heads, max_len, dropout_rate, device, pad_token_idx, mask_token_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_items = num_items\n",
    "        self.hidden_units = hidden_units\n",
    "        self.pad_token_idx = pad_token_idx\n",
    "        self.mask_token_idx = mask_token_idx # Use dynamically set MASK index\n",
    "        self.device = device\n",
    "\n",
    "        # Embedding layers: vocab size needs num_items + PAD (0) + MASK (num_items + 1) = num_items + 2\n",
    "        self.item_embedding = nn.Embedding(num_items + 2, hidden_units, padding_idx=self.pad_token_idx)\n",
    "        self.position_embedding = nn.Embedding(max_len, hidden_units)\n",
    "        self.embedding_dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_units,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_units * 4,\n",
    "            dropout=dropout_rate,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_blocks,\n",
    "            norm=nn.LayerNorm(hidden_units) # Final norm\n",
    "        )\n",
    "\n",
    "        # Output layer maps hidden state to item scores (predict items 1 to num_items)\n",
    "        # Output size should be num_items + 1 to map to indices 1..num_items\n",
    "        # We map to indices 0..num_items, where 0 corresponds to item 1, ..., num_items-1 to item N\n",
    "        # The loss function will handle the index mapping if needed, or we adjust targets.\n",
    "        # Simpler: Output size = num_items + 2 (raw logits for PAD, items 1..N, MASK)\n",
    "        # Then filter in loss calculation. Let's try outputting num_items + 1 (scores for items 1..N)\n",
    "        # We need scores for items 1 to num_items. The target labels are also 1 to num_items.\n",
    "        # The vocab size of the output layer needs to match the range of target labels.\n",
    "        # Target labels range from 1 to num_items. PAD is 0.\n",
    "        # Output layer needs to predict scores for indices 1 to num_items.\n",
    "        # Size = num_items + 1 allows predicting index 0 (PAD) up to num_items.\n",
    "        self.output_layer = nn.Linear(hidden_units, num_items + 1) # Predict scores for indices 0..num_items\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            stddev = 0.02\n",
    "            module.weight.data.normal_(mean=0.0, std=stddev)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.Embedding) and module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids shape: (batch_size, max_len)\n",
    "\n",
    "        # Create padding mask for transformer (True where padded)\n",
    "        attention_mask = (input_ids == self.pad_token_idx) # Shape: (batch_size, max_len)\n",
    "\n",
    "        # Embeddings\n",
    "        item_emb = self.item_embedding(input_ids)\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=self.device).unsqueeze(0) # Shape: (1, max_len)\n",
    "        pos_emb = self.position_embedding(position_ids)\n",
    "\n",
    "        # Combine and dropout\n",
    "        sequence_emb = item_emb + pos_emb\n",
    "        sequence_emb = self.embedding_dropout(sequence_emb)\n",
    "\n",
    "        # Transformer forward pass\n",
    "        transformer_output = self.transformer_encoder(\n",
    "            src=sequence_emb,\n",
    "            src_key_padding_mask=attention_mask\n",
    "        ) # Shape: (batch_size, max_len, hidden_units)\n",
    "\n",
    "        # Output logits\n",
    "        logits = self.output_layer(transformer_output) # Shape: (batch_size, max_len, num_items + 1)\n",
    "\n",
    "        return logits\n",
    "\n",
    "print(\"BERT4Rec model class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oNCoG8aqARVo",
    "outputId": "4e1e4792-1f2a-471b-fa72-840cbf03e823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility function defined.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Utility function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q-tMinliAS2v",
    "outputId": "2dc4b102-d281-4f02-f8fc-7c95e7fa48ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device selected: cuda\n",
      "Device Name: NVIDIA A100-SXM4-40GB\n",
      "Memory Allocated: 0.0 MB\n",
      "Memory Cached: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Execution device selected: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.1f} MB\")\n",
    "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0)/1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9518ecd277c64030a5b26241b923af2b"
     ]
    },
    "id": "3qMq1uJ0AUAM",
    "outputId": "bf09b577-044a-409d-81c6-7e1a74fc5f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading and preprocessing...\n",
      "Dataset found at ./data_bert4rec/ml-20m/ratings.csv\n",
      "Loading and preprocessing data...\n",
      "Initial ratings: 20000263\n",
      "Ratings after user filtering: 20000263 (138493 users)\n",
      "Ratings after item filtering: 19984024 (18345 items)\n",
      "Ratings after re-filtering users: 19984024 (138493 users)\n",
      "Number of unique users: 138493\n",
      "Number of unique items (vocab size): 18345\n",
      "MASK token index set to: 18346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa406bbc2d04732ba90674cf5ca39dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating sequences: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences generated: 19845531\n",
      "Train sequences: 17860977\n",
      "Validation sequences: 1984554\n",
      "------------------------------\n",
      "Data preprocessing finished.\n",
      "Number of items (vocab size): 18345\n",
      "Mask token index: 18346\n",
      "Number of training sequences: 17860977\n",
      "Number of validation sequences: 1984554\n"
     ]
    }
   ],
   "source": [
    "# This cell might take a while to run, especially the first time or with large datasets\n",
    "print(\"Starting data loading and preprocessing...\")\n",
    "download_and_extract_data(config)\n",
    "train_sequences, val_sequences, num_items, mask_token_idx = preprocess_data(config)\n",
    "\n",
    "# Ensure the config object used later has the correct MASK index\n",
    "config.MASK = mask_token_idx\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Data preprocessing finished.\")\n",
    "print(f\"Number of items (vocab size): {num_items}\")\n",
    "print(f\"Mask token index: {config.MASK}\")\n",
    "print(f\"Number of training sequences: {len(train_sequences)}\")\n",
    "print(f\"Number of validation sequences: {len(val_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B9eV8jElAVja",
    "outputId": "573435b5-24b4-4c43-a042-6f9b17452874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PyTorch Datasets and DataLoaders...\n",
      "DataLoaders created.\n",
      "Train batches per epoch: 34885\n",
      "Validation batches per epoch: 3877\n",
      "\n",
      "Sample Batch Shapes:\n",
      "Input IDs: torch.Size([512, 50])\n",
      "Labels: torch.Size([512, 50])\n",
      "Sample Input: tensor([ 1523,   582,   562,   572,   907,  1484,  1552,  3450, 18346, 18346,\n",
      "         3493,  2587,  1540, 18346,  2263])\n",
      "Sample Labels: tensor([   0,    0,    0,    0,    0,    0,    0,    0,   42, 1493,    0,    0,\n",
      "           0, 2089,    0])\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating PyTorch Datasets and DataLoaders...\")\n",
    "\n",
    "train_dataset = MLDataset(\n",
    "    train_sequences,\n",
    "    config.max_len,\n",
    "    config.mask_prob,\n",
    "    config.MASK,\n",
    "    config.PAD,\n",
    "    num_items\n",
    ")\n",
    "val_dataset = MLDataset(\n",
    "    val_sequences,\n",
    "    config.max_len,\n",
    "    config.mask_prob, # Use same masking approach for validation loss consistency\n",
    "    config.MASK,\n",
    "    config.PAD,\n",
    "    num_items\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    "    persistent_workers=True if config.num_workers > 0 else False # Can speed up epoch start\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True if device.type == 'cuda' else False,\n",
    "    persistent_workers=True if config.num_workers > 0 else False\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created.\")\n",
    "print(f\"Train batches per epoch: {len(train_loader)}\")\n",
    "print(f\"Validation batches per epoch: {len(val_loader)}\")\n",
    "\n",
    "# Optional: Check a sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"\\nSample Batch Shapes:\")\n",
    "print(\"Input IDs:\", sample_batch['input_ids'].shape)\n",
    "print(\"Labels:\", sample_batch['labels'].shape)\n",
    "print(\"Sample Input:\", sample_batch['input_ids'][0,:15])\n",
    "print(\"Sample Labels:\", sample_batch['labels'][0,:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XWjqE5tZAXIr",
    "outputId": "867fe753-c946-4824-b26a-3368b882a240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model, Optimizer, and Loss Function...\n",
      "Model Initialized on cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tt2884/.local/lib/python3.9/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled with torch.compile().\n",
      "Number of trainable parameters: 5,118,250\n",
      "Optimizer: AdamW\n",
      "Loss Function: CrossEntropyLoss (ignores padding)\n",
      "\n",
      "Initializing WandB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtt2884\u001b[0m (\u001b[33mtt2884-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tt2884/wandb/run-20250420_191553-8ypybj5u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1/runs/8ypybj5u' target=\"_blank\">bert4rec_ml20m_20250420_191350</a></strong> to <a href='https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1' target=\"_blank\">https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1/runs/8ypybj5u' target=\"_blank\">https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1/runs/8ypybj5u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run initialized. Tracking run: https://wandb.ai/tt2884-new-york-university/BERT4Rec-MovieLens_opt1/runs/8ypybj5u\n",
      "WandB model watch enabled.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Model, Optimizer, and Loss Function...\")\n",
    "\n",
    "model = BERT4Rec(\n",
    "    num_items=num_items, hidden_units=config.hidden_units, num_blocks=config.num_blocks,\n",
    "    num_heads=config.num_heads, max_len=config.max_len, dropout_rate=config.dropout_rate,\n",
    "    device=device, pad_token_idx=config.PAD, mask_token_idx=config.MASK\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model Initialized on {device}.\")\n",
    "\n",
    "# --- Compile the model (PyTorch 2.0+) --- <<< ADDED\n",
    "try:\n",
    "    # Options: 'default', 'reduce-overhead', 'max-autotune'\n",
    "    model = torch.compile(model, mode='reduce-overhead')\n",
    "    print(\"Model compiled with torch.compile().\")\n",
    "except Exception as e:\n",
    "    print(f\"torch.compile() failed: {e}. Proceeding without compilation.\")\n",
    "# --- End Compilation ---\n",
    "\n",
    "param_count = count_parameters(model)\n",
    "print(f\"Number of trainable parameters: {param_count:,}\")\n",
    "if param_count >= 5_000_000_000:\n",
    "     print(\"Warning: Model parameter count exceeds 5 billion!\")\n",
    "\n",
    "# Optimizer\n",
    "if config.optimizer_type.lower() == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "elif config.optimizer_type.lower() == 'adamw':\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported optimizer type\")\n",
    "print(f\"Optimizer: {config.optimizer_type}\")\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=config.PAD)\n",
    "print(\"Loss Function: CrossEntropyLoss (ignores padding)\")\n",
    "\n",
    "\n",
    "# --- Initialize Weights & Biases\n",
    "print(\"\\nInitializing WandB...\")\n",
    "try:\n",
    "    wandb_run = wandb.init(\n",
    "        project=config.WANDB_PROJECT,\n",
    "        entity=config.WANDB_ENTITY, # Optional: remove if using default entity\n",
    "        name=config.RUN_NAME,       # Set run name\n",
    "        config=vars(config),        # Log all hyperparameters from the config object\n",
    "        job_type=\"training\"         # Optional: categorize run\n",
    "    )\n",
    "    print(f\"WandB run initialized. Tracking run: {wandb_run.url}\")\n",
    "\n",
    "    # Optional: Watch the model to log gradients and parameter histograms\n",
    "    wandb.watch(model, log=\"gradients\", log_freq=100) # Log gradients every 100 steps\n",
    "    print(\"WandB model watch enabled.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing WandB: {e}\")\n",
    "    print(\"WandB logging will be disabled for this run.\")\n",
    "    wandb_run = None # Ensure wandb_run is None if init fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7c365bb384874d23b542de97e450046c"
     ]
    },
    "id": "oAg6I3J1AYvj",
    "outputId": "e8937630-2b97-4eca-e61e-c14256987888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Profiler enabled. Results will be saved to ./log_bert4rec\n",
      "Profiling schedule: Wait=1, Warmup=10, Active=50, Repeat=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5552/2629553672.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=torch.cuda.is_available()) # Enable only if using CUDA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff628698c3494055abbbb987f2507cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n",
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n",
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f20c254b6a445d3bdd26c9b73a55916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5 [Validate]:   0%|          | 0/3877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tt2884/.local/lib/python3.9/site-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Duration: 0:20:05\n",
      "  Average Training Loss: 5.5649\n",
      "  Average Validation Loss: 5.1307\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad499edfb2204104a58b6a84f9adfccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n",
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cdabbe35e74fedacc95640a7864c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5 [Validate]:   0%|          | 0/3877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Duration: 0:19:35\n",
      "  Average Training Loss: 5.3378\n",
      "  Average Validation Loss: 5.0664\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6773af514ff475f877701b4e42c4e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0375adce5a457e92700c78aae4129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5 [Validate]:   0%|          | 0/3877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Duration: 0:15:23\n",
      "  Average Training Loss: 5.2928\n",
      "  Average Validation Loss: 5.0252\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf513b53cdc46d0a306c861fd9b489c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de3da78036640409f291d74f588281a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5 [Validate]:   0%|          | 0/3877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "  Duration: 0:15:57\n",
      "  Average Training Loss: 5.2687\n",
      "  Average Validation Loss: 5.0050\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36391bf56e7449a19ca84b6058f3a9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5552/2629553672.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc12ac28a7f4c19b129f36aadcb9830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5 [Validate]:   0%|          | 0/3877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "  Duration: 0:14:48\n",
      "  Average Training Loss: 5.2555\n",
      "  Average Validation Loss: 4.9915\n",
      "------------------------------\n",
      "Profiling finished. Trace saved.\n",
      "\n",
      "Total Training finished in: 1:25:50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m    133\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m--> 134\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), validation_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    136\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/axes/_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available()) # Enable only if using CUDA\n",
    "\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "global_step = 0\n",
    "# No need for these lists if logging primarily to WandB\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Setup Profiler if enabled (can run alongside WandB)\n",
    "profiler = None\n",
    "if config.profiler_enabled:\n",
    "    os.makedirs(config.profile_dir, exist_ok=True)\n",
    "    profiler_schedule = torch.profiler.schedule(wait=1, warmup=config.profile_warmup, active=config.profile_batches, repeat=1)\n",
    "    profiler = profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == 'cuda' else [ProfilerActivity.CPU],\n",
    "        schedule=profiler_schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(config.profile_dir),\n",
    "        record_shapes=True, profile_memory=True, with_stack=False\n",
    "    )\n",
    "    print(f\"Profiler enabled. Results will be saved to {config.profile_dir}\")\n",
    "    print(f\"Profiling schedule: Wait=1, Warmup={config.profile_warmup}, Active={config.profile_batches}, Repeat=1\")\n",
    "    profiler.start()\n",
    "\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    pbar = tqdm(enumerate(train_loader), total=num_batches, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\")\n",
    "\n",
    "    for batch_idx, batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Use autocast for forward pass and loss calculation\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "          with record_function(\"model_forward\"):\n",
    "              logits = model(input_ids) # Shape: (batch_size, max_len, num_items + 1)\n",
    "\n",
    "          logits_flat = logits.view(-1, logits.size(-1))\n",
    "          labels_flat = labels.view(-1)\n",
    "\n",
    "          with record_function(\"loss_computation\"):\n",
    "              loss = criterion(logits_flat, labels_flat)\n",
    "\n",
    "        # Scale loss and call backward\n",
    "        with record_function(\"backward_pass\"):\n",
    "             scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscale gradients and step optimizer\n",
    "        with record_function(\"optimizer_step\"):\n",
    "             scaler.step(optimizer)\n",
    "             scaler.update() # Update scale for next iteration\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        epoch_loss += current_loss\n",
    "        global_step += 1\n",
    "\n",
    "        # Log batch loss to WandB and console periodically <<< WANDB LOGGING\n",
    "        if wandb_run and (batch_idx % config.log_freq == 0 or batch_idx == num_batches - 1):\n",
    "            wandb.log({\n",
    "                \"train/batch_loss\": current_loss,\n",
    "                \"global_step\": global_step,\n",
    "                # Optional: Log learning rate if it changes\n",
    "                \"train/learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            avg_loss_so_far = epoch_loss / (batch_idx + 1)\n",
    "            pbar.set_postfix(loss=f\"{avg_loss_so_far:.4f}\", current_loss=f\"{current_loss:.4f}\")\n",
    "        elif batch_idx % config.log_freq == 0 or batch_idx == num_batches - 1:\n",
    "             # Update console even if WandB failed\n",
    "             avg_loss_so_far = epoch_loss / (batch_idx + 1)\n",
    "             pbar.set_postfix(loss=f\"{avg_loss_so_far:.4f}\", current_loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "\n",
    "        if profiler:\n",
    "             profiler.step()\n",
    "\n",
    "    avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = len(val_loader)\n",
    "    val_pbar = tqdm(val_loader, total=val_batches, desc=f\"Epoch {epoch+1}/{config.epochs} [Validate]\")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            labels = batch['labels'].to(device, non_blocking=True)\n",
    "            logits = model(input_ids)\n",
    "            logits_flat = logits.view(-1, logits.size(-1))\n",
    "            labels_flat = labels.view(-1)\n",
    "            loss = criterion(logits_flat, labels_flat)\n",
    "            val_loss += loss.item()\n",
    "            val_pbar.set_postfix(loss=f\"{(val_loss / (val_pbar.n + 1)):.4f}\")\n",
    "\n",
    "    avg_val_loss = val_loss / val_batches\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Log epoch metrics to WandB <<< WANDB LOGGING\n",
    "    epoch_metrics = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train/avg_loss\": avg_train_loss,\n",
    "        \"val/avg_loss\": avg_val_loss,\n",
    "        \"epoch/duration_sec\": epoch_duration\n",
    "    }\n",
    "    if wandb_run:\n",
    "        wandb.log(epoch_metrics)\n",
    "\n",
    "    # Also print to console\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Duration: {str(datetime.timedelta(seconds=int(epoch_duration)))}\")\n",
    "    print(f\"  Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "\n",
    "if profiler:\n",
    "    profiler.stop()\n",
    "    print(\"Profiling finished. Trace saved.\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"\\nTotal Training finished in: {str(datetime.timedelta(seconds=int(total_time)))}\")\n",
    "\n",
    "# Optional: Plot losses - WandB provides better interactive plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, config.epochs + 1), training_losses, label='Training Loss')\n",
    "plt.plot(range(1, config.epochs + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Finish WandB Run ---\n",
    "if wandb_run:\n",
    "    print(\"Finishing WandB run...\")\n",
    "    wandb.finish()\n",
    "    print(\"WandB run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QZm-dFxQAc1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved locally to ./data_bert4rec/checkpoints/bert4rec_ml-20m_e5.pth\n",
      "Model checkpoint uploaded to WandB run.\n",
      "Saving model as WandB Artifact...\n",
      "Model artifact saved to WandB.\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Standard PyTorch Save + wandb.save (Uploads the local file)\n",
    "save_dir = os.path.join(config.DATA_DIR, \"checkpoints\")\n",
    "os.makedirs(save_dir, exist_ok=True) # Create directory if it doesn't exist\n",
    "save_path = os.path.join(save_dir, f\"bert4rec_{config.DATASET_NAME}_e{config.epochs}.pth\")\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': config.epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': vars(config),\n",
    "    'num_items': num_items,\n",
    "    'mask_token_idx': config.MASK\n",
    "}\n",
    "torch.save(checkpoint, save_path)\n",
    "print(f\"Model checkpoint saved locally to {save_path}\")\n",
    "\n",
    "# Upload the saved checkpoint file to the current WandB run\n",
    "if wandb_run:\n",
    "     try:\n",
    "         wandb.save(save_path, base_path=config.DATA_DIR) # Saves file relative to DATA_DIR in WandB artifacts\n",
    "         print(f\"Model checkpoint uploaded to WandB run.\")\n",
    "     except Exception as e:\n",
    "         print(f\"Could not upload checkpoint to WandB: {e}\")\n",
    "\n",
    "\n",
    "# Option 2: Using WandB Artifacts (More robust versioning)\n",
    "if wandb_run:\n",
    "    print(\"Saving model as WandB Artifact...\")\n",
    "    artifact = wandb.Artifact(f'bert4rec-{config.RUN_NAME}', type='model', metadata=vars(config))\n",
    "    torch.save(model.state_dict(), 'model.pth') # Save model state dict locally first\n",
    "    artifact.add_file('model.pth') # Add the file to the artifact\n",
    "    # Save other necessary info like num_items, mask_token_idx if needed for reloading\n",
    "    # with artifact.new_file('model_info.json', mode='w') as f:\n",
    "    #     import json\n",
    "    #     json.dump({'num_items': num_items, 'mask_token_idx': config.MASK}, f)\n",
    "\n",
    "    wandb_run.log_artifact(artifact) # Log the artifact to the run\n",
    "    print(\"Model artifact saved to WandB.\")\n",
    "    os.remove('model.pth') # Clean up local file after logging artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
