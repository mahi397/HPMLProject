{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNuJ8Q66ssB",
        "collapsed": true,
        "outputId": "110c7d49-ae56-49bb-d0a2-dc8401b6419c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in /home/ms15532/.local/lib/python3.9/site-packages (2.6.0)\n",
            "Requirement already satisfied: pandas in /home/ms15532/.local/lib/python3.9/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /home/ms15532/.local/lib/python3.9/site-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (4.61.2)\n",
            "Requirement already satisfied: scikit-learn in /home/ms15532/.local/lib/python3.9/site-packages (1.6.1)\n",
            "Requirement already satisfied: notebook in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (7.0.7)\n",
            "Requirement already satisfied: ipywidgets in /home/ms15532/.local/lib/python3.9/site-packages (8.1.6)\n",
            "Requirement already satisfied: tensorboard in /home/ms15532/.local/lib/python3.9/site-packages (2.18.0)\n",
            "Requirement already satisfied: wandb in /home/ms15532/.local/lib/python3.9/site-packages (0.19.9)\n",
            "Requirement already satisfied: filelock in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (2025.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/ms15532/.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ms15532/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/ms15532/.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/ms15532/.local/lib/python3.9/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ms15532/.local/lib/python3.9/site-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/ms15532/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/ms15532/.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ms15532/.local/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (2.12.5)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (2.25.2)\n",
            "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (4.0.12)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (0.2.3)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from notebook) (6.4)\n",
            "Requirement already satisfied: comm>=0.1.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipywidgets) (5.14.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/ms15532/.local/lib/python3.9/site-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /home/ms15532/.local/lib/python3.9/site-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: packaging in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (5.29.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (52.0.0.post20210125)\n",
            "Requirement already satisfied: six>1.9 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/ms15532/.local/lib/python3.9/site-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: eval-type-backport in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (0.2.2)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (4.2.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: pydantic<3 in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /home/ms15532/.local/lib/python3.9/site-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ms15532/.local/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: decorator in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
            "Requirement already satisfied: stack-data in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: exceptiongroup in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (8.6.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.7.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.9.0)\n",
            "Requirement already satisfied: jupyter-server-terminals in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.5.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.14.2)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.9.2)\n",
            "Requirement already satisfied: overrides in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.19.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.1.2)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.18.0)\n",
            "Requirement already satisfied: websocket-client in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.7.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (7.0.1)\n",
            "Requirement already satisfied: ipykernel in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (6.29.0)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.2.2)\n",
            "Requirement already satisfied: tomli in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab<5,>=4.0.2->notebook) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: babel>=2.10 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (2.14.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (0.9.14)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.22.1->notebook) (4.21.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/ms15532/.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /home/ms15532/.local/lib/python3.9/site-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ms15532/.local/lib/python3.9/site-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ms15532/.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyterlab<5,>=4.0.2->notebook) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook) (0.17.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.0.7)\n",
            "Requirement already satisfied: rfc3339-validator in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.19.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (1.8.0)\n",
            "Requirement already satisfied: nest-asyncio in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from ipykernel->jupyterlab<5,>=4.0.2->notebook) (1.6.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: webencodings in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
            "Requirement already satisfied: fqdn in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.4)\n",
            "Requirement already satisfied: uri-template in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.5)\n",
            "Requirement already satisfied: pycparser in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook) (2.20)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.8.19.20240106)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch pandas numpy requests tqdm scikit-learn notebook ipywidgets tensorboard wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4bh6GjyAEzy",
        "outputId": "172df05c-e24e-456e-d9b5-96bd46585017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.6.0+cu124\n",
            "WandB Version: 0.19.9\n",
            "CUDA Available: True\n",
            "CUDA Version: 12.4\n",
            "Device Name: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from tqdm.notebook import tqdm # Use tqdm.notebook for Jupyter!\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import datetime\n",
        "import warnings\n",
        "import wandb\n",
        "\n",
        "# Ignore specific warnings if needed\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"WandB Version: {wandb.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# (Optional) Login to WandB if you haven't via CLI\n",
        "# try:\n",
        "#     wandb.login()\n",
        "# except Exception as e:\n",
        "#     print(f\"Could not automatically log in to WandB: {e}\")\n",
        "#     print(\"Please ensure you have run 'wandb login' in your terminal or manually call wandb.login() here.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMBD4eT2AHVi",
        "outputId": "4159754b-773c-4302-d9ae-b076f6515a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration set.\n",
            "WandB Project: BERT4Rec-MovieLens\n",
            "Run Name: bert4rec_ml20m_20250420_173433\n",
            "Batch Size: 512\n",
            "Hidden Units: 128\n",
            "Num Workers: 8\n",
            "Using AdamW optimizer.\n"
          ]
        }
      ],
      "source": [
        "class Config:\n",
        "    # WandB parameters\n",
        "    WANDB_PROJECT = \"BERT4Rec-MovieLens\" # Project name on WandB\n",
        "    WANDB_ENTITY = None # Your WandB username or team (optional, defaults to your default entity)\n",
        "    RUN_NAME = f\"bert4rec_ml20m_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\" # Unique run name\n",
        "\n",
        "    # Data parameters\n",
        "    DATASET_NAME = \"ml-20m\"\n",
        "    DATA_URL = f\"https://files.grouplens.org/datasets/movielens/{DATASET_NAME}.zip\"\n",
        "    DATA_DIR = \"./data_bert4rec\"\n",
        "    RATINGS_FILE = f\"{DATASET_NAME}/ratings.csv\"\n",
        "    MIN_USER_INTERACTIONS = 5\n",
        "    MIN_ITEM_INTERACTIONS = 5\n",
        "    TEST_NEG_SAMPLE_SIZE = 100\n",
        "\n",
        "    # Model parameters\n",
        "    max_len = 50\n",
        "    hidden_units = 128\n",
        "    num_blocks = 2\n",
        "    num_heads = 4\n",
        "    dropout_rate = 0.2\n",
        "    mask_prob = 0.2\n",
        "\n",
        "    # Training parameters\n",
        "    epochs = 5\n",
        "    batch_size = 512 # Increased for V100/A100\n",
        "    lr = 1e-3\n",
        "    optimizer_type = 'AdamW'\n",
        "    weight_decay = 0.01\n",
        "    num_workers = 8\n",
        "    log_freq = 50 # Log batch loss every N batches to WandB/console\n",
        "    profiler_enabled = True # Keep profiler if needed alongside WandB\n",
        "    profile_batches = 50\n",
        "    profile_warmup = 10\n",
        "    profile_dir = \"./log_bert4rec\"\n",
        "\n",
        "    # Special token indices\n",
        "    PAD = 0\n",
        "    MASK = -1\n",
        "\n",
        "# Instantiate config\n",
        "config = Config()\n",
        "\n",
        "# --- Sanity Checks ---\n",
        "if config.hidden_units % config.num_heads != 0:\n",
        "    raise ValueError(f\"hidden_units ({config.hidden_units}) must be divisible by num_heads ({config.num_heads})\")\n",
        "\n",
        "print(\"Configuration set.\")\n",
        "print(f\"WandB Project: {config.WANDB_PROJECT}\")\n",
        "print(f\"Run Name: {config.RUN_NAME}\")\n",
        "print(f\"Batch Size: {config.batch_size}\")\n",
        "print(f\"Hidden Units: {config.hidden_units}\")\n",
        "print(f\"Num Workers: {config.num_workers}\")\n",
        "print(f\"Using {config.optimizer_type} optimizer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGSVMutiAJk_",
        "outputId": "0d2d493b-4778-4009-e723-065ae2eefd3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data download function defined.\n"
          ]
        }
      ],
      "source": [
        "def download_and_extract_data(config):\n",
        "    \"\"\"Downloads and extracts the MovieLens dataset.\"\"\"\n",
        "    os.makedirs(config.DATA_DIR, exist_ok=True)\n",
        "    zip_path = os.path.join(config.DATA_DIR, f\"{config.DATASET_NAME}.zip\")\n",
        "    extract_path = os.path.join(config.DATA_DIR)\n",
        "    ratings_path = os.path.join(config.DATA_DIR, config.RATINGS_FILE)\n",
        "\n",
        "    if not os.path.exists(ratings_path):\n",
        "        print(f\"Downloading {config.DATASET_NAME} dataset...\")\n",
        "        response = requests.get(config.DATA_URL, stream=True)\n",
        "        response.raise_for_status()\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024 # 1 Kibibyte\n",
        "        # Use tqdm for download progress\n",
        "        progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True, desc=\"Downloading\")\n",
        "        with open(zip_path, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=block_size):\n",
        "                progress_bar.update(len(chunk))\n",
        "                f.write(chunk)\n",
        "        progress_bar.close()\n",
        "        if total_size != 0 and progress_bar.n != total_size:\n",
        "             print(\"ERROR, something went wrong during download\")\n",
        "\n",
        "        print(\"Download complete. Extracting...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(\"Extraction complete.\")\n",
        "        os.remove(zip_path) # Clean up zip file\n",
        "    else:\n",
        "        print(f\"Dataset found at {ratings_path}\")\n",
        "\n",
        "print(\"Data download function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ITC-eHjALeE",
        "outputId": "6d8ac846-105c-4f35-e075-084b3e916749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preprocessing function defined.\n"
          ]
        }
      ],
      "source": [
        "def preprocess_data(config):\n",
        "    \"\"\"Loads ratings, filters users/items, creates sequences.\"\"\"\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    ratings_df = pd.read_csv(os.path.join(config.DATA_DIR, config.RATINGS_FILE))\n",
        "    print(f\"Initial ratings: {len(ratings_df)}\")\n",
        "\n",
        "    # Filter users\n",
        "    user_counts = ratings_df['userId'].value_counts()\n",
        "    valid_users = user_counts[user_counts >= config.MIN_USER_INTERACTIONS].index\n",
        "    ratings_df = ratings_df[ratings_df['userId'].isin(valid_users)]\n",
        "    print(f\"Ratings after user filtering: {len(ratings_df)} ({len(valid_users)} users)\")\n",
        "\n",
        "    # Filter items\n",
        "    item_counts = ratings_df['movieId'].value_counts()\n",
        "    valid_items = item_counts[item_counts >= config.MIN_ITEM_INTERACTIONS].index\n",
        "    ratings_df = ratings_df[ratings_df['movieId'].isin(valid_items)]\n",
        "    print(f\"Ratings after item filtering: {len(ratings_df)} ({len(valid_items)} items)\")\n",
        "\n",
        "    # Re-filter users\n",
        "    user_counts = ratings_df['userId'].value_counts()\n",
        "    valid_users = user_counts[user_counts >= config.MIN_USER_INTERACTIONS].index\n",
        "    ratings_df = ratings_df[ratings_df['userId'].isin(valid_users)]\n",
        "    print(f\"Ratings after re-filtering users: {len(ratings_df)} ({len(valid_users)} users)\")\n",
        "\n",
        "    # Sort interactions\n",
        "    ratings_df = ratings_df.sort_values(by=['userId', 'timestamp'])\n",
        "\n",
        "    # Create mappings (item IDs start from 1)\n",
        "    unique_users = ratings_df['userId'].unique()\n",
        "    user_map = {user_id: i for i, user_id in enumerate(unique_users)}\n",
        "    unique_items = ratings_df['movieId'].unique()\n",
        "    item_map = {item_id: i + 1 for i, item_id in enumerate(unique_items)}\n",
        "    num_items = len(item_map)\n",
        "    config.MASK = num_items + 1 # Set MASK token index dynamically in the shared config object\n",
        "\n",
        "    print(f\"Number of unique users: {len(user_map)}\")\n",
        "    print(f\"Number of unique items (vocab size): {num_items}\")\n",
        "    print(f\"MASK token index set to: {config.MASK}\")\n",
        "\n",
        "    # Group interactions and create sequences\n",
        "    user_sequences = ratings_df.groupby('userId')['movieId'].apply(list)\n",
        "    processed_sequences = []\n",
        "    for user_id, item_sequence in tqdm(user_sequences.items(), desc=\"Generating sequences\"):\n",
        "        mapped_sequence = [item_map[item] for item in item_sequence]\n",
        "        # Create subsequences ending at each point\n",
        "        for i in range(1, len(mapped_sequence)): # Start from 1 to have at least one item as label\n",
        "            end_idx = i + 1\n",
        "            start_idx = max(0, end_idx - config.max_len)\n",
        "            seq = mapped_sequence[start_idx:end_idx]\n",
        "\n",
        "            # Pad sequence\n",
        "            padded_seq = ([config.PAD] * (config.max_len - len(seq))) + seq\n",
        "            if len(padded_seq) != config.max_len:\n",
        "                 print(f\"Padding Error: User {user_id}, i={i}, len={len(padded_seq)}\")\n",
        "                 continue\n",
        "\n",
        "            processed_sequences.append(padded_seq)\n",
        "\n",
        "    print(f\"Total number of sequences generated: {len(processed_sequences)}\")\n",
        "\n",
        "    # Split data (user-agnostic split for simplicity here)\n",
        "    random.shuffle(processed_sequences)\n",
        "    split_idx = int(len(processed_sequences) * 0.9)\n",
        "    train_sequences = processed_sequences[:split_idx]\n",
        "    val_sequences = processed_sequences[split_idx:]\n",
        "\n",
        "    print(f\"Train sequences: {len(train_sequences)}\")\n",
        "    print(f\"Validation sequences: {len(val_sequences)}\")\n",
        "\n",
        "    return train_sequences, val_sequences, num_items, config.MASK # Return MASK index\n",
        "\n",
        "print(\"Data preprocessing function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgh7ZQMXANaS",
        "outputId": "fab111b4-628f-4782-d512-4e669335da38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLDataset class defined.\n"
          ]
        }
      ],
      "source": [
        "class MLDataset(Dataset):\n",
        "    \"\"\"MovieLens Dataset for BERT4Rec training.\"\"\"\n",
        "    def __init__(self, sequences, max_len, mask_prob, mask_token_idx, pad_token_idx, num_items):\n",
        "        self.sequences = sequences\n",
        "        self.max_len = max_len\n",
        "        self.mask_prob = mask_prob\n",
        "        self.mask_token_idx = mask_token_idx\n",
        "        self.pad_token_idx = pad_token_idx\n",
        "        self.num_items = num_items # Actual number of items (vocab size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx] # Sequence of item IDs (padded)\n",
        "        masked_input_seq = list(seq)\n",
        "        labels = [self.pad_token_idx] * self.max_len # Target labels (only for masked positions)\n",
        "\n",
        "        # Identify positions eligible for masking (not PAD)\n",
        "        eligible_indices = [i for i, token in enumerate(seq) if token != self.pad_token_idx]\n",
        "        num_eligible = len(eligible_indices)\n",
        "        num_items_to_mask = max(1, math.ceil(self.mask_prob * num_eligible)) # Ensure at least one item is masked if possible\n",
        "\n",
        "        if num_eligible > 0:\n",
        "            # Randomly select indices to mask from eligible ones\n",
        "            indices_to_mask = random.sample(eligible_indices, min(num_items_to_mask, num_eligible))\n",
        "\n",
        "            for i in indices_to_mask:\n",
        "                original_item = seq[i]\n",
        "                labels[i] = original_item # Set the label to the original item\n",
        "\n",
        "                # Apply masking strategy to the input sequence\n",
        "                prob = random.random()\n",
        "                if prob < 0.8: # 80% chance: Replace with MASK token\n",
        "                    masked_input_seq[i] = self.mask_token_idx\n",
        "                elif prob < 0.9: # 10% chance: Replace with random item\n",
        "                    random_item = random.randint(1, self.num_items) # Items are 1 to num_items\n",
        "                    # Ensure random item isn't the original or PAD/MASK\n",
        "                    while random_item == original_item:\n",
        "                         random_item = random.randint(1, self.num_items)\n",
        "                    masked_input_seq[i] = random_item\n",
        "                # else: 10% chance: Keep original item (implicitly handled)\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(masked_input_seq, dtype=torch.long),\n",
        "            'labels': torch.tensor(labels, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "print(\"MLDataset class defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHVpWJD1APWO",
        "outputId": "50b73ca4-988f-4381-eea8-e7df792db643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT4Rec model class defined.\n"
          ]
        }
      ],
      "source": [
        "class BERT4Rec(nn.Module):\n",
        "    def __init__(self, num_items, hidden_units, num_blocks, num_heads, max_len, dropout_rate, device, pad_token_idx, mask_token_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_items = num_items\n",
        "        self.hidden_units = hidden_units\n",
        "        self.pad_token_idx = pad_token_idx\n",
        "        self.mask_token_idx = mask_token_idx # Use dynamically set MASK index\n",
        "        self.device = device\n",
        "\n",
        "        # Embedding layers: vocab size needs num_items + PAD (0) + MASK (num_items + 1) = num_items + 2\n",
        "        self.item_embedding = nn.Embedding(num_items + 2, hidden_units, padding_idx=self.pad_token_idx)\n",
        "        self.position_embedding = nn.Embedding(max_len, hidden_units)\n",
        "        self.embedding_dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_units,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_units * 4,\n",
        "            dropout=dropout_rate,\n",
        "            activation='gelu',\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=num_blocks,\n",
        "            norm=nn.LayerNorm(hidden_units) # Final norm\n",
        "        )\n",
        "\n",
        "        # Output layer maps hidden state to item scores (predict items 1 to num_items)\n",
        "        # Output size should be num_items + 1 to map to indices 1..num_items\n",
        "        # We map to indices 0..num_items, where 0 corresponds to item 1, ..., num_items-1 to item N\n",
        "        # The loss function will handle the index mapping if needed, or we adjust targets.\n",
        "        # Simpler: Output size = num_items + 2 (raw logits for PAD, items 1..N, MASK)\n",
        "        # Then filter in loss calculation. Let's try outputting num_items + 1 (scores for items 1..N)\n",
        "        # We need scores for items 1 to num_items. The target labels are also 1 to num_items.\n",
        "        # The vocab size of the output layer needs to match the range of target labels.\n",
        "        # Target labels range from 1 to num_items. PAD is 0.\n",
        "        # Output layer needs to predict scores for indices 1 to num_items.\n",
        "        # Size = num_items + 1 allows predicting index 0 (PAD) up to num_items.\n",
        "        self.output_layer = nn.Linear(hidden_units, num_items + 1) # Predict scores for indices 0..num_items\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            stddev = 0.02\n",
        "            module.weight.data.normal_(mean=0.0, std=stddev)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.Embedding) and module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids shape: (batch_size, max_len)\n",
        "\n",
        "        # Create padding mask for transformer (True where padded)\n",
        "        attention_mask = (input_ids == self.pad_token_idx) # Shape: (batch_size, max_len)\n",
        "\n",
        "        # Embeddings\n",
        "        item_emb = self.item_embedding(input_ids)\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=self.device).unsqueeze(0) # Shape: (1, max_len)\n",
        "        pos_emb = self.position_embedding(position_ids)\n",
        "\n",
        "        # Combine and dropout\n",
        "        sequence_emb = item_emb + pos_emb\n",
        "        sequence_emb = self.embedding_dropout(sequence_emb)\n",
        "\n",
        "        # Transformer forward pass\n",
        "        transformer_output = self.transformer_encoder(\n",
        "            src=sequence_emb,\n",
        "            src_key_padding_mask=attention_mask\n",
        "        ) # Shape: (batch_size, max_len, hidden_units)\n",
        "\n",
        "        # Output logits\n",
        "        logits = self.output_layer(transformer_output) # Shape: (batch_size, max_len, num_items + 1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "print(\"BERT4Rec model class defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNCoG8aqARVo",
        "outputId": "4e1e4792-1f2a-471b-fa72-840cbf03e823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utility function defined.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Utility function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-tMinliAS2v",
        "outputId": "2dc4b102-d281-4f02-f8fc-7c95e7fa48ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution device selected: cuda\n",
            "Device Name: NVIDIA A100-SXM4-40GB\n",
            "Memory Allocated: 0.0 MB\n",
            "Memory Cached: 0.0 MB\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Execution device selected: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.1f} MB\")\n",
        "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0)/1024**2:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qMq1uJ0AUAM",
        "colab": {
          "referenced_widgets": [
            "9518ecd277c64030a5b26241b923af2b"
          ]
        },
        "outputId": "bf09b577-044a-409d-81c6-7e1a74fc5f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data loading and preprocessing...\n",
            "Dataset found at ./data_bert4rec/ml-20m/ratings.csv\n",
            "Loading and preprocessing data...\n",
            "Initial ratings: 20000263\n",
            "Ratings after user filtering: 20000263 (138493 users)\n",
            "Ratings after item filtering: 19984024 (18345 items)\n",
            "Ratings after re-filtering users: 19984024 (138493 users)\n",
            "Number of unique users: 138493\n",
            "Number of unique items (vocab size): 18345\n",
            "MASK token index set to: 18346\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.008253097534179688,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Generating sequences",
              "rate": null,
              "total": null,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9518ecd277c64030a5b26241b923af2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating sequences: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of sequences generated: 19845531\n",
            "Train sequences: 17860977\n",
            "Validation sequences: 1984554\n",
            "------------------------------\n",
            "Data preprocessing finished.\n",
            "Number of items (vocab size): 18345\n",
            "Mask token index: 18346\n",
            "Number of training sequences: 17860977\n",
            "Number of validation sequences: 1984554\n"
          ]
        }
      ],
      "source": [
        "# This cell might take a while to run, especially the first time or with large datasets\n",
        "print(\"Starting data loading and preprocessing...\")\n",
        "download_and_extract_data(config)\n",
        "train_sequences, val_sequences, num_items, mask_token_idx = preprocess_data(config)\n",
        "\n",
        "# Ensure the config object used later has the correct MASK index\n",
        "config.MASK = mask_token_idx\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(\"Data preprocessing finished.\")\n",
        "print(f\"Number of items (vocab size): {num_items}\")\n",
        "print(f\"Mask token index: {config.MASK}\")\n",
        "print(f\"Number of training sequences: {len(train_sequences)}\")\n",
        "print(f\"Number of validation sequences: {len(val_sequences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9eV8jElAVja",
        "outputId": "573435b5-24b4-4c43-a042-6f9b17452874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating PyTorch Datasets and DataLoaders...\n",
            "DataLoaders created.\n",
            "Train batches per epoch: 34885\n",
            "Validation batches per epoch: 3877\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating PyTorch Datasets and DataLoaders...\")\n",
        "\n",
        "train_dataset = MLDataset(\n",
        "    train_sequences,\n",
        "    config.max_len,\n",
        "    config.mask_prob,\n",
        "    config.MASK,\n",
        "    config.PAD,\n",
        "    num_items\n",
        ")\n",
        "val_dataset = MLDataset(\n",
        "    val_sequences,\n",
        "    config.max_len,\n",
        "    config.mask_prob, # Use same masking approach for validation loss consistency\n",
        "    config.MASK,\n",
        "    config.PAD,\n",
        "    num_items\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=config.num_workers,\n",
        "    pin_memory=True if device.type == 'cuda' else False,\n",
        "    persistent_workers=True if config.num_workers > 0 else False # Can speed up epoch start\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=config.num_workers,\n",
        "    pin_memory=True if device.type == 'cuda' else False,\n",
        "    persistent_workers=True if config.num_workers > 0 else False\n",
        ")\n",
        "\n",
        "print(\"DataLoaders created.\")\n",
        "print(f\"Train batches per epoch: {len(train_loader)}\")\n",
        "print(f\"Validation batches per epoch: {len(val_loader)}\")\n",
        "\n",
        "# Optional: Check a sample batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(\"\\nSample Batch Shapes:\")\n",
        "print(\"Input IDs:\", sample_batch['input_ids'].shape)\n",
        "print(\"Labels:\", sample_batch['labels'].shape)\n",
        "print(\"Sample Input:\", sample_batch['input_ids'][0,:15])\n",
        "print(\"Sample Labels:\", sample_batch['labels'][0,:15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWjqE5tZAXIr",
        "outputId": "867fe753-c946-4824-b26a-3368b882a240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Model, Optimizer, and Loss Function...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ms15532/.local/lib/python3.9/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Initialized on cuda.\n",
            "Number of trainable parameters: 5,118,250\n",
            "Optimizer: AdamW\n",
            "Loss Function: CrossEntropyLoss (ignores padding)\n",
            "\n",
            "Initializing WandB...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mms15532\u001b[0m (\u001b[33mms15532-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/scratch/ms15532/wandb/run-20250420_173622-4dpqydv1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens/runs/4dpqydv1' target=\"_blank\">bert4rec_ml20m_20250420_173433</a></strong> to <a href='https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens' target=\"_blank\">https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens/runs/4dpqydv1' target=\"_blank\">https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens/runs/4dpqydv1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WandB run initialized. Tracking run: https://wandb.ai/ms15532-new-york-university/BERT4Rec-MovieLens/runs/4dpqydv1\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing Model, Optimizer, and Loss Function...\")\n",
        "\n",
        "model = BERT4Rec(\n",
        "    num_items=num_items, hidden_units=config.hidden_units, num_blocks=config.num_blocks,\n",
        "    num_heads=config.num_heads, max_len=config.max_len, dropout_rate=config.dropout_rate,\n",
        "    device=device, pad_token_idx=config.PAD, mask_token_idx=config.MASK\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model Initialized on {device}.\")\n",
        "\n",
        "# --- Compile the model (PyTorch 2.0+) --- <<< ADDED\n",
        "try:\n",
        "    # Options: 'default', 'reduce-overhead', 'max-autotune'\n",
        "    model = torch.compile(model, mode='reduce-overhead')\n",
        "    print(\"Model compiled with torch.compile().\")\n",
        "except Exception as e:\n",
        "    print(f\"torch.compile() failed: {e}. Proceeding without compilation.\")\n",
        "# --- End Compilation ---\n",
        "\n",
        "param_count = count_parameters(model)\n",
        "print(f\"Number of trainable parameters: {param_count:,}\")\n",
        "if param_count >= 5_000_000_000:\n",
        "     print(\"Warning: Model parameter count exceeds 5 billion!\")\n",
        "\n",
        "# Optimizer\n",
        "if config.optimizer_type.lower() == 'adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "elif config.optimizer_type.lower() == 'adamw':\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported optimizer type\")\n",
        "print(f\"Optimizer: {config.optimizer_type}\")\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=config.PAD)\n",
        "print(\"Loss Function: CrossEntropyLoss (ignores padding)\")\n",
        "\n",
        "\n",
        "# --- Initialize Weights & Biases\n",
        "print(\"\\nInitializing WandB...\")\n",
        "try:\n",
        "    wandb_run = wandb.init(\n",
        "        project=config.WANDB_PROJECT,\n",
        "        entity=config.WANDB_ENTITY, # Optional: remove if using default entity\n",
        "        name=config.RUN_NAME,       # Set run name\n",
        "        config=vars(config),        # Log all hyperparameters from the config object\n",
        "        job_type=\"training\"         # Optional: categorize run\n",
        "    )\n",
        "    print(f\"WandB run initialized. Tracking run: {wandb_run.url}\")\n",
        "\n",
        "    # Optional: Watch the model to log gradients and parameter histograms\n",
        "    wandb.watch(model, log=\"gradients\", log_freq=100) # Log gradients every 100 steps\n",
        "    print(\"WandB model watch enabled.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing WandB: {e}\")\n",
        "    print(\"WandB logging will be disabled for this run.\")\n",
        "    wandb_run = None # Ensure wandb_run is None if init fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAg6I3J1AYvj",
        "colab": {
          "referenced_widgets": [
            "7c365bb384874d23b542de97e450046c"
          ]
        },
        "outputId": "e8937630-2b97-4eca-e61e-c14256987888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Profiler enabled. Results will be saved to ./log_bert4rec\n",
            "Profiling schedule: Wait=1, Warmup=10, Active=50, Repeat=1\n"
          ]
        },
        {
          "data": {
            "application/json": {
              "ascii": false,
              "bar_format": null,
              "colour": null,
              "elapsed": 0.16554665565490723,
              "initial": 0,
              "n": 0,
              "ncols": null,
              "nrows": null,
              "postfix": null,
              "prefix": "Epoch 1/5 [Train]",
              "rate": null,
              "total": 34885,
              "unit": "it",
              "unit_divisor": 1000,
              "unit_scale": false
            },
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c365bb384874d23b542de97e450046c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/5 [Train]:   0%|          | 0/34885 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler(enabled=torch.cuda.is_available()) # Enable only if using CUDA\n",
        "\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "global_step = 0\n",
        "# No need for these lists if logging primarily to WandB\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "# Setup Profiler if enabled (can run alongside WandB)\n",
        "profiler = None\n",
        "if config.profiler_enabled:\n",
        "    os.makedirs(config.profile_dir, exist_ok=True)\n",
        "    profiler_schedule = torch.profiler.schedule(wait=1, warmup=config.profile_warmup, active=config.profile_batches, repeat=1)\n",
        "    profiler = profile(\n",
        "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA] if device.type == 'cuda' else [ProfilerActivity.CPU],\n",
        "        schedule=profiler_schedule,\n",
        "        on_trace_ready=torch.profiler.tensorboard_trace_handler(config.profile_dir),\n",
        "        record_shapes=True, profile_memory=True, with_stack=False\n",
        "    )\n",
        "    print(f\"Profiler enabled. Results will be saved to {config.profile_dir}\")\n",
        "    print(f\"Profiling schedule: Wait=1, Warmup={config.profile_warmup}, Active={config.profile_batches}, Repeat=1\")\n",
        "    profiler.start()\n",
        "\n",
        "\n",
        "for epoch in range(config.epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = len(train_loader)\n",
        "    pbar = tqdm(enumerate(train_loader), total=num_batches, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\")\n",
        "\n",
        "    for batch_idx, batch in pbar:\n",
        "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "        labels = batch['labels'].to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Use autocast for forward pass and loss calculation\n",
        "        with autocast(enabled=torch.cuda.is_available()):\n",
        "          with record_function(\"model_forward\"):\n",
        "              logits = model(input_ids) # Shape: (batch_size, max_len, num_items + 1)\n",
        "\n",
        "          logits_flat = logits.view(-1, logits.size(-1))\n",
        "          labels_flat = labels.view(-1)\n",
        "\n",
        "          with record_function(\"loss_computation\"):\n",
        "              loss = criterion(logits_flat, labels_flat)\n",
        "\n",
        "        # Scale loss and call backward\n",
        "        with record_function(\"backward_pass\"):\n",
        "             scaler.scale(loss).backward()\n",
        "\n",
        "        # Unscale gradients and step optimizer\n",
        "        with record_function(\"optimizer_step\"):\n",
        "             scaler.step(optimizer)\n",
        "             scaler.update() # Update scale for next iteration\n",
        "\n",
        "        current_loss = loss.item()\n",
        "        epoch_loss += current_loss\n",
        "        global_step += 1\n",
        "\n",
        "        # Log batch loss to WandB and console periodically <<< WANDB LOGGING\n",
        "        if wandb_run and (batch_idx % config.log_freq == 0 or batch_idx == num_batches - 1):\n",
        "            wandb.log({\n",
        "                \"train/batch_loss\": current_loss,\n",
        "                \"global_step\": global_step,\n",
        "                # Optional: Log learning rate if it changes\n",
        "                \"train/learning_rate\": optimizer.param_groups[0]['lr']\n",
        "            })\n",
        "            avg_loss_so_far = epoch_loss / (batch_idx + 1)\n",
        "            pbar.set_postfix(loss=f\"{avg_loss_so_far:.4f}\", current_loss=f\"{current_loss:.4f}\")\n",
        "        elif batch_idx % config.log_freq == 0 or batch_idx == num_batches - 1:\n",
        "             # Update console even if WandB failed\n",
        "             avg_loss_so_far = epoch_loss / (batch_idx + 1)\n",
        "             pbar.set_postfix(loss=f\"{avg_loss_so_far:.4f}\", current_loss=f\"{current_loss:.4f}\")\n",
        "\n",
        "\n",
        "        if profiler:\n",
        "             profiler.step()\n",
        "\n",
        "    avg_train_loss = epoch_loss / num_batches\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_batches = len(val_loader)\n",
        "    val_pbar = tqdm(val_loader, total=val_batches, desc=f\"Epoch {epoch+1}/{config.epochs} [Validate]\")\n",
        "    with torch.no_grad():\n",
        "        for batch in val_pbar:\n",
        "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "            labels = batch['labels'].to(device, non_blocking=True)\n",
        "            logits = model(input_ids)\n",
        "            logits_flat = logits.view(-1, logits.size(-1))\n",
        "            labels_flat = labels.view(-1)\n",
        "            loss = criterion(logits_flat, labels_flat)\n",
        "            val_loss += loss.item()\n",
        "            val_pbar.set_postfix(loss=f\"{(val_loss / (val_pbar.n + 1)):.4f}\")\n",
        "\n",
        "    avg_val_loss = val_loss / val_batches\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "\n",
        "    # Log epoch metrics to WandB <<< WANDB LOGGING\n",
        "    epoch_metrics = {\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train/avg_loss\": avg_train_loss,\n",
        "        \"val/avg_loss\": avg_val_loss,\n",
        "        \"epoch/duration_sec\": epoch_duration\n",
        "    }\n",
        "    if wandb_run:\n",
        "        wandb.log(epoch_metrics)\n",
        "\n",
        "    # Also print to console\n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"  Duration: {str(datetime.timedelta(seconds=int(epoch_duration)))}\")\n",
        "    print(f\"  Average Training Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "if profiler:\n",
        "    profiler.stop()\n",
        "    print(\"Profiling finished. Trace saved.\")\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"\\nTotal Training finished in: {str(datetime.timedelta(seconds=int(total_time)))}\")\n",
        "\n",
        "# Optional: Plot losses - WandB provides better interactive plots\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, config.epochs + 1), training_losses, label='Training Loss')\n",
        "plt.plot(range(1, config.epochs + 1), validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Finish WandB Run ---\n",
        "if wandb_run:\n",
        "    print(\"Finishing WandB run...\")\n",
        "    wandb.finish()\n",
        "    print(\"WandB run finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZm-dFxQAc1j"
      },
      "outputs": [],
      "source": [
        "# Option 1: Standard PyTorch Save + wandb.save (Uploads the local file)\n",
        "save_dir = os.path.join(config.DATA_DIR, \"checkpoints\")\n",
        "os.makedirs(save_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "save_path = os.path.join(save_dir, f\"bert4rec_{config.DATASET_NAME}_e{config.epochs}.pth\")\n",
        "\n",
        "checkpoint = {\n",
        "    'epoch': config.epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'config': vars(config),\n",
        "    'num_items': num_items,\n",
        "    'mask_token_idx': config.MASK\n",
        "}\n",
        "torch.save(checkpoint, save_path)\n",
        "print(f\"Model checkpoint saved locally to {save_path}\")\n",
        "\n",
        "# Upload the saved checkpoint file to the current WandB run\n",
        "if wandb_run:\n",
        "     try:\n",
        "         wandb.save(save_path, base_path=config.DATA_DIR) # Saves file relative to DATA_DIR in WandB artifacts\n",
        "         print(f\"Model checkpoint uploaded to WandB run.\")\n",
        "     except Exception as e:\n",
        "         print(f\"Could not upload checkpoint to WandB: {e}\")\n",
        "\n",
        "\n",
        "# Option 2: Using WandB Artifacts (More robust versioning)\n",
        "if wandb_run:\n",
        "    print(\"Saving model as WandB Artifact...\")\n",
        "    artifact = wandb.Artifact(f'bert4rec-{config.RUN_NAME}', type='model', metadata=vars(config))\n",
        "    torch.save(model.state_dict(), 'model.pth') # Save model state dict locally first\n",
        "    artifact.add_file('model.pth') # Add the file to the artifact\n",
        "    # Save other necessary info like num_items, mask_token_idx if needed for reloading\n",
        "    # with artifact.new_file('model_info.json', mode='w') as f:\n",
        "    #     import json\n",
        "    #     json.dump({'num_items': num_items, 'mask_token_idx': config.MASK}, f)\n",
        "\n",
        "    wandb_run.log_artifact(artifact) # Log the artifact to the run\n",
        "    print(\"Model artifact saved to WandB.\")\n",
        "    os.remove('model.pth') # Clean up local file after logging artifact"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}